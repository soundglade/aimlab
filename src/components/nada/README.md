# Nada - Guided Meditation Generator

Nada is an experimental tool inside AIM Lab that allows users to synthesize guided meditations from a text-based meditation script (likely generated by ChatGPT or other LLMs). It transforms text-based meditation scripts into formatted and narrated audio meditations.

## Features

- **Script Formatting**: Converts raw meditation scripts into structured, formatted content
- **Voice Selection**: Choose from a variety of voice options for narration
- **Audio Synthesis**: Generates high-quality audio narration of meditation scripts
- **Session Management**: Save and retrieve meditation sessions
- **Private Mode**: Option to use the application without saving any data

## Architecture

### Core Components

1. **NadaPage (`NadaPage.tsx`)**:

   - Main container component that manages the application state and workflow
   - Handles session management and persistence
   - Coordinates the different steps of the meditation creation process

2. **PracticeSetup (`PracticeSetup.tsx`)**:

   - Initial step for inputting meditation scripts
   - Provides options for private vs. saved sessions
   - Submits scripts for formatting via API

3. **FormattedMeditation (`FormattedMeditation.tsx`)**:

   - Displays the formatted meditation script
   - Allows users to review and confirm the formatted content

4. **VoiceSelection (`VoiceSelection.tsx`)**:

   - Interface for selecting voice options for audio narration
   - Provides both basic and advanced voice customization options

5. **SynthesisProgress (`SynthesisProgress.tsx`)**:
   - Manages the audio synthesis process
   - Displays progress and provides playback controls for the generated audio

### Backend API Interactions

The frontend communicates with two simple API endpoints:

1. **Script Formatting** (`/api/format-meditation-script`):

   - Takes a raw meditation script and transforms it into a structured format
   - Uses OpenAI's GPT model to intelligently parse and structure the meditation content
   - Identifies different elements in the script such as:
     - Speech sections (narration to be spoken aloud)
     - Headings and titles (with different importance levels)
     - Pauses (with appropriate durations)
     - Sound cues (like bells or chimes)
     - Directions (performance instructions)
     - Asides (notes not meant to be spoken)
   - Validates the script to ensure it's suitable for meditation purposes
   - Returns a well-organized structure that enhances the meditation experience

2. **Audio Synthesis** (`/api/synthesize-meditation`):
   - Converts the formatted script into spoken audio using the selected voice
   - Provides real-time progress updates during the synthesis process
   - Returns audio data for each section as it's generated
   - Allows for immediate playback while the rest of the meditation is being processed

### Routing

- `/nada`: Main entry point for creating new meditation sessions
- `/nada/[id]`: Dynamic route for accessing saved meditation sessions

### Data Flow

1. User inputs a meditation script in the PracticeSetup component
2. Script is sent to the server for formatting via `/api/format-meditation-script`
3. Formatted script is displayed for review in the FormattedMeditation component
4. User selects voice options in the VoiceSelection component
5. Audio is synthesized with progress tracking in the SynthesisProgress component
6. Final meditation can be played, downloaded, or saved for future sessions

### Session Management

- Sessions are stored in browser localStorage using a custom storage utility
- Each session has a unique ID that can be used to retrieve it later
- Private sessions are not persisted and leave no trace

## Development Guidelines

- Follow the AIM Lab Frontend Conventions for code style and organization
- Use functional programming patterns and React hooks for state management
- Maintain the calm, mindful aesthetic throughout the UI
- Ensure responsive design for all screen sizes
